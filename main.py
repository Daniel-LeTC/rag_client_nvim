import os
import sys
import warnings

from langchain_chroma import Chroma
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_ollama import ChatOllama, OllamaEmbeddings

from config import COLLECTION_NAME, EMBEDDING_MODEL_NAME, MODEL_NAME, POLY_SYSTEM_PROMPT, VECTOR_DB_PATH

warnings.filterwarnings("ignore")


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


def main():
    if not os.path.exists(VECTOR_DB_PATH):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y Database t·∫°i {VECTOR_DB_PATH}!")
        return

    print(f"‚ö° ƒê√£ t√¨m th·∫•y DB t·∫°i {VECTOR_DB_PATH}. Load h√†ng n√≥ng...")

    try:
        embedding_function = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME)
        vectorstore = Chroma(
            persist_directory=VECTOR_DB_PATH, embedding_function=embedding_function, collection_name=COLLECTION_NAME
        )
    except Exception as e:
        print(f"üíÄ L·ªói load DB: {e}")
        return

    # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ rerank (k=30)
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 30})

    print("üß† ƒêang t·∫£i Reranker...")
    try:
        model_kwargs = {"device": "cpu"}
        reranker = HuggingFaceCrossEncoder(model_name="BAAI/bge-reranker-base", model_kwargs=model_kwargs)
        print("‚úÖ Reranker ƒë√£ s·∫µn s√†ng (CPU Mode).")
    except Exception as e:
        print(f"‚ö†Ô∏è  Kh√¥ng load ƒë∆∞·ª£c Reranker: {e}")
        reranker = None

    print(f"ü§ñ ƒêang k√≠ch ho·∫°t n√£o b·ªô: {MODEL_NAME}...")
    llm = ChatOllama(model=MODEL_NAME, temperature=0, keep_alive="1h")
    prompt = ChatPromptTemplate.from_template(POLY_SYSTEM_PROMPT)

    print("\n" + "=" * 40)
    print("üí¨ POLYMATH BRO IS ONLINE (G√µ 'q' ƒë·ªÉ t√©)")
    print("=" * 40)

    while True:
        try:
            query = input("\nM√†y: ").strip()
            if query.lower() in ["q", "quit", "exit"]:
                print("üëã Bye bro.")
                break
            if not query:
                continue

            print(f"\nüîç ƒêang b·ªõi th√πng r√°c t√¨m: '{query}'...")

            # --- RAG PIPELINE ---
            retrieved_docs = retriever.invoke(query)

            final_docs = []
            if reranker:
                try:
                    pairs = [[query, doc.page_content] for doc in retrieved_docs]
                    scores = reranker.score(pairs)

                    scored_docs = sorted(zip(retrieved_docs, scores), key=lambda x: x[1], reverse=True)

                    print("   üìä Reranker Debug (Top 5):")

                    # --- N·ªöI L·ªéNG NG∆Ø·ª†NG L·ªåC ---
                    # H·∫° xu·ªëng -10.0 ƒë·ªÉ h·∫ßu nh∆∞ kh√¥ng l·ªçc g√¨ c·∫£, tr·ª´ khi qu√° t·ªá
                    THRESHOLD = -10.0

                    for i, (doc, score) in enumerate(scored_docs[:7]):
                        src = os.path.basename(doc.metadata.get("source", "Unknown"))
                        print(f"      [{i + 1}] Score: {score:.4f} | Source: {src}")

                        if score > THRESHOLD:
                            final_docs.append(doc)
                        else:
                            print(f"      ‚ùå [Lo·∫°i b·ªè do th·∫•p h∆°n {THRESHOLD}]")

                    if not final_docs and scored_docs:
                        print("      ‚ö†Ô∏è L·∫•y t·∫°m th·∫±ng ƒë·∫ßu ti√™n d√π ƒëi·ªÉm th·∫•p.")
                        final_docs = [scored_docs[0][0]]

                except Exception as e:
                    print(f"L·ªói Rerank: {e}")
                    final_docs = retrieved_docs[:5]
            else:
                final_docs = retrieved_docs[:5]

            if not final_docs:
                print("\nü§ñ Polymath Bot:")
                print("-" * 30)
                print("Tao ch·ªãu. Kh√¥ng t√¨m th·∫•y th√¥ng tin n√†o kh·ªõp c·∫£.")
                print("-" * 30)
                continue

            context_text = format_docs(final_docs)
            chain = prompt | llm | StrOutputParser()

            print("\nü§ñ Polymath Bot:")
            print("-" * 30)

            for chunk in chain.stream({"context": context_text, "question": query}):
                print(chunk, end="", flush=True)

            print("\n" + "-" * 30)

            # Show Sources
            print("üìö Ngu·ªìn d·ªØ li·ªáu (Evidence):")
            seen_sources = set()
            for i, doc in enumerate(final_docs):
                source = os.path.basename(doc.metadata.get("source", "Unknown"))
                if source not in seen_sources:
                    print(f"   [{i + 1}] {source}")
                    seen_sources.add(source)
            print("-" * 30)

        except KeyboardInterrupt:
            print("\nüëã Bye!")
            break
        except Exception as e:
            print(f"\n‚ùå L·ªói: {e}")


if __name__ == "__main__":
    main()
