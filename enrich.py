import argparse
import hashlib
import os
import re
import sys
import textwrap

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import ChatOllama

# --- C·∫§U H√åNH ---
DEFAULT_NOTE_PATH = "/home/daniel/Projects/mind_dump/"
LLM_MODEL = "llama3.2:3b"

# --- REGEX PH√ÇN LO·∫†I FILE ---
# T√™n file ki·ªÉu 8 ch·ªØ s·ªë, v√≠ d·ª•: 20251213.md (d√†nh cho Daily Dump/Chaos)
DAILY_DUMP_PATTERN = re.compile(r"^\d{8}\.md$", re.IGNORECASE)

# --- A. PROMPT CHO FILE D√ÄI (CHUY√äN GIA / DEEP RESEARCH) ---
DETAIL_TEMPLATE = """
B·∫°n l√† Tr·ª£ l√Ω Ph√¢n t√≠ch Ki·∫øn th·ª©c. T√†i li·ªáu n√†y l√† ki·∫øn th·ª©c C·∫§U TR√öC.
Y√äU C·∫¶U:
1. T·∫°o m·ªôt b·∫£n **T√ìM T·∫ÆT CHI TI·∫æT** (t·ª´ 2-3 c√¢u) c√°c √Ω ch√≠nh, thu·∫≠t to√°n, ho·∫∑c c√¥ng th·ª©c quan tr·ªçng.
2. T·∫°o **M·ªòT DANH S√ÅCH DUY NH·∫§T** g·ªìm 10-15 t·ª´ kh√≥a bao qu√°t **ph·∫°m vi (DOMAIN)** c·ªßa t√†i li·ªáu. C√°c t·ª´ kh√≥a ph·∫£i thu·ªôc c·∫•p ƒë·ªô lƒ©nh v·ª±c (v√≠ d·ª•: 'Transformer', 'Attention Mechanism').

FORMAT OUTPUT:
Summary: [T√≥m t·∫Øt chi ti·∫øt]
Keywords: [Keyword list]

N·ªôi dung:
{text}
"""

# --- B. PROMPT CHO FILE NG·∫ÆN (CHAOS / DAILY DUMP) ---
SIMPLE_TEMPLATE = """
B·∫°n l√† Tr·ª£ l√Ω RAG cho ghi ch√∫ c√° nh√¢n. T√†i li·ªáu n√†y l√† ghi ch√∫ H·ªñN LO·∫†N, d√πng ƒë·ªÉ ghi nh·ªõ nhanh.
Y√äU C·∫¶U:
1. T√≥m t·∫Øt n·ªôi dung ch√≠nh trong **ƒê√öNG 1 C√ÇU TI·∫æNG VI·ªÜT** (c·ª±c k·ª≥ ng·∫Øn g·ªçn).
2. T·∫°o **M·ªòT DANH S√ÅCH DUY NH·∫§T** g·ªìm 10-15 t·ª´ kh√≥a, t·∫≠p trung v√†o **c√°c th·ª±c th·ªÉ (ENTITY)** ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn (v√≠ d·ª•: t√™n ng∆∞·ªùi, s·∫£n ph·∫©m, h√†nh ƒë·ªông, c·∫£m x√∫c). Kh√¥ng c·∫ßn t·ª´ kh√≥a Domain n·∫øu kh√¥ng r√µ r√†ng.

FORMAT OUTPUT:
Summary: [T√≥m t·∫Øt 1 c√¢u]
Keywords: [Keyword list]

N·ªôi dung:
{text}
"""


def calculate_md5(text):
    """T√≠nh m√£ bƒÉm MD5 c·ªßa vƒÉn b·∫£n ƒë·ªÉ ki·ªÉm tra thay ƒë·ªïi"""
    return hashlib.md5(text.strip().encode("utf-8")).hexdigest()


def enrich_notes(note_path):
    """
    ƒêi tu·∫ßn tra c√°c file .md, ph√¢n lo·∫°i theo t√™n file (YYYYMMDD.md vs T√™n_Kh√°c.md).
    """

    if not os.path.exists(note_path):
        return 0

    print(f"üîå ƒêang k·∫øt n·ªëi v·ªõi n√£o b·ªô Ollama ({LLM_MODEL})...")
    try:
        llm = ChatOllama(model=LLM_MODEL, temperature=0)
    except Exception as e:
        print(f"‚ùå Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Ollama: {e}")
        return 0

    metadata_pattern = re.compile(r"\n+\s*<!-- AI_METADATA\n(.*?)\n\s*-->", re.DOTALL)

    print(f"üïµÔ∏è  ƒêang r√† so√°t thay ƒë·ªïi t·∫°i: {note_path}")
    processed_count = 0
    skipped_count = 0

    for root, dirs, files in os.walk(note_path):
        for file in files:
            if file.endswith(".md"):
                file_path = os.path.join(root, file)
                filename = os.path.basename(file_path)  # L·∫•y t√™n file ƒë·ªÉ ki·ªÉm tra

                try:
                    with open(file_path, encoding="utf-8") as f:
                        full_content = f.read()

                    # 1. T√°ch n·ªôi dung g·ªëc
                    match = metadata_pattern.search(full_content)
                    user_content = full_content[: match.start()].strip() if match else full_content.strip()

                    if len(user_content) < 10:
                        continue

                    current_hash = calculate_md5(user_content)

                    # 2. KI·ªÇM TRA HASH C≈® (Logic Versioning)
                    if match:
                        old_metadata_block = match.group(1)
                        hash_match = re.search(r"Content-Hash: ([a-f0-9]+)", old_metadata_block)
                        old_hash = hash_match.group(1) if hash_match else "old"

                        if current_hash == old_hash:
                            skipped_count += 1
                            continue
                        else:
                            print(f"üìù Ph√°t hi·ªán thay ƒë·ªïi trong: {file}. Re-indexing...")
                    else:
                        print(f"üî® File m·ªõi: {file}. ƒêang x·ª≠ l√Ω...")

                    # 3. CH·ªåN PROMPT D·ª∞A TR√äN T√äN FILE (LOGIC M·ªöI C·ª¶A M√ÄY)
                    if DAILY_DUMP_PATTERN.match(filename):
                        template = SIMPLE_TEMPLATE
                        print(f"  [MODE: CHAOS] (Daily Dump: {filename})")
                    else:
                        template = DETAIL_TEMPLATE
                        print(f"  [MODE: EXPERT] (Structured: {filename})")

                    prompt = ChatPromptTemplate.from_template(template)
                    chain = prompt | llm | StrOutputParser()

                    # 4. G·ªçi AI x·ª≠ l√Ω
                    ai_response = chain.invoke({"text": user_content})

                    # 5. Ghi ƒë√® l·∫°i file
                    new_metadata = textwrap.dedent(f"""
                        <!-- AI_METADATA
                        Content-Hash: {current_hash}
                        {ai_response.strip()}
                        -->""")

                    with open(file_path, "w", encoding="utf-8") as f:
                        f.write(user_content + "\n\n" + new_metadata.strip())

                    print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t Metadata cho {file}")
                    processed_count += 1

                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói file {file}: {e}")

    print("-" * 30)
    print(f"üéâ Ho√†n t·∫•t! Update: {processed_count} | Skip: {skipped_count}")
    return processed_count


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--path", type=str, default=DEFAULT_NOTE_PATH)
    args = parser.parse_args()
    enrich_notes(args.path)
