ğŸ§  Polymath Second Brain - Local RAG Setup

Há»‡ thá»‘ng Second Brain cháº¡y local 100%, sá»­ dá»¥ng Neovim Ä‘á»ƒ ghi chÃº vÃ  AI Ä‘á»ƒ tÃ¬m kiáº¿m/tá»•ng há»£p thÃ´ng tin.

ğŸ› ï¸ YÃªu cáº§u há»‡ thá»‘ng (Prerequisites)

OS: Linux (Fedora/Ubuntu/Arch...) hoáº·c WSL2.

GPU: NVIDIA RTX 3060 (6GB VRAM) trá»Ÿ lÃªn lÃ  mÆ°á»£t.

Python: 3.10+ (KhuyÃªn dÃ¹ng uv Ä‘á»ƒ quáº£n lÃ½ package).

ğŸ¦™ 1. CÃ i Ä‘áº·t Ollama (AI Engine)

Cháº¡y lá»‡nh sau Ä‘á»ƒ cÃ i Ä‘áº·t (Script chÃ­nh chá»§ cá»§a Ollama):

curl -fsSL [https://ollama.com/install.sh](https://ollama.com/install.sh) | sh


Quáº£n lÃ½ Service (Systemd)

Sau khi cÃ i xong, Ä‘áº£m báº£o Ollama cháº¡y ngáº§m cÃ¹ng há»‡ thá»‘ng:

# Khá»Ÿi Ä‘á»™ng service
sudo systemctl start ollama

# Báº­t tá»± Ä‘á»™ng cháº¡y khi má»Ÿ mÃ¡y
sudo systemctl enable ollama


Check tráº¡ng thÃ¡i: systemctl status ollama

ğŸ“¥ 2. Táº£i Models (The Brains)

ChÃºng ta cáº§n 2 model: má»™t cÃ¡i Ä‘á»ƒ NghÄ© (LLM) vÃ  má»™t cÃ¡i Ä‘á»ƒ NhÃ¬n (Embedding).

A. LLM Model: Llama 3.2 3B

LÃ½ do: Nhá», nháº¹, nhanh, context window lá»›n (128k), cháº¡y mÆ°á»£t trÃªn Laptop GPU 6GB mÃ  khÃ´ng lÃ m nÃ³ng mÃ¡y.

ollama pull llama3.2:3b


B. Embedding Model: mxbai-embed-large

LÃ½ do: Tá»‘t nháº¥t trong táº§m giÃ¡ cho RAG. Há»— trá»£ Ä‘a ngÃ´n ngá»¯ tá»‘t hÆ¡n nomic, hiá»ƒu ngá»¯ nghÄ©a sÃ¢u hÆ¡n. Dimension 1024.

ollama pull mxbai-embed-large


ğŸš€ 3. CÃ i Ä‘áº·t Python Dependencies

Dá»± Ã¡n nÃ y dÃ¹ng uv cho sáº¡ch sáº½ vÃ  nhanh.

# 1. CÃ i uv (náº¿u chÆ°a cÃ³)
curl -LsSf [https://astral.sh/uv/install.sh](https://astral.sh/uv/install.sh) | sh

# 2. Sync thÆ° viá»‡n
uv sync


ğŸ® 4. Sá»­ dá»¥ng

Cháº¡y thá»§ cÃ´ng (Terminal):

# Chat tá»± Ä‘á»™ng (tá»± check file má»›i, tá»± bÆ¡m metadata, tá»± git push)
uv run smart_run.py

# Chat vá»›i cÃ¢u há»i cá»¥ thá»ƒ
uv run smart_run.py "ghi chÃº há»—n loáº¡n lÃ  gÃ¬?"


Cháº¡y trong Neovim:

:Ask <cÃ¢u há»i>: Má»Ÿ cá»­a sá»• chat Floating Window.

:Enrich: Cháº¡y tool bÆ¡m Metadata thá»§ cÃ´ng.

Created by Polymath Bro Architecture.
